import requests
import pandas as pd
import os
import logging
from datetime import datetime


# ğŸ“ è·¯å¾‘è¨­å®š
DATA_DIR = "data"
DATA_DIR2 = "logs"
CSV_FILE = os.path.join(DATA_DIR, "0050_twse.csv")
LOG_FILE = os.path.join(DATA_DIR2, "update.log")

# ğŸ“ è¨­å®š loggingï¼ˆé¿å…äº‚ç¢¼ï¼Œç”¨ utf-8-sigï¼‰
log_handler = logging.FileHandler(LOG_FILE, mode="a", encoding="utf-8-sig")
logging.basicConfig(
    handlers=[log_handler],
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)


# ğŸ§® å–å¾— API æ‰€éœ€æ—¥æœŸï¼ˆç•¶æœˆç¬¬ä¸€å¤©ï¼Œè¥¿å…ƒå¹´æœˆæ—¥ï¼‰
def get_twse_date():
    today = datetime.today()
    return f"{today.year}{today.month:02d}01"  # ä¾‹å¦‚ 20250901


# ğŸ“¦ æŠ“å– TWSE è³‡æ–™
def fetch_twse_data(date_str):
    url = f"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=json&date={date_str}&stockNo=0050"
    try:
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        data = res.json()
        if "data" not in data or not data["data"]:
            logging.warning("TWSE å›å‚³è³‡æ–™ç‚ºç©º")
            return None
        return data["data"]
    except Exception as e:
        logging.error(f"æŠ“å– TWSE è³‡æ–™å¤±æ•—ï¼š{e}")
        return None


# ğŸ§¼ æ¸…æ´—è³‡æ–™ï¼ˆæ°‘åœ‹æ—¥æœŸ â†’ è¥¿å…ƒæ—¥æœŸï¼‰
def clean_data(raw_data):
    columns = [
        "æ—¥æœŸ",
        "æˆäº¤è‚¡æ•¸",
        "æˆäº¤é‡‘é¡",
        "é–‹ç›¤åƒ¹",
        "æœ€é«˜åƒ¹",
        "æœ€ä½åƒ¹",
        "æ”¶ç›¤åƒ¹",
        "æ¼²è·Œåƒ¹å·®",
        "æˆäº¤ç­†æ•¸",
    ]
    df = pd.DataFrame(raw_data, columns=columns)

    # æ°‘åœ‹ â†’ è¥¿å…ƒ
    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].apply(
        lambda x: str(int(x.split("/")[0]) + 1911)
        + "/"
        + x.split("/")[1]
        + "/"
        + x.split("/")[2]
    )
    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"], format="%Y/%m/%d")

    # æ•¸å€¼æ¬„ä½æ¸…ç†
    for col in columns[1:]:
        df[col] = df[col].astype(str).str.replace(",", "").astype(float)

    return df


# ğŸ§  ä¸»æµç¨‹
def update_twse():
    os.makedirs(DATA_DIR, exist_ok=True)
    date_str = get_twse_date()
    raw_data = fetch_twse_data(date_str)
    if raw_data is None:
        logging.warning("æœªå–å¾—æ–°è³‡æ–™ï¼Œè·³éæ›´æ–°")
        return

    df_new = clean_data(raw_data)

    if os.path.exists(CSV_FILE):
        df_old = pd.read_csv(CSV_FILE, encoding="utf-8-sig", parse_dates=["æ—¥æœŸ"])
        df_combined = pd.concat([df_old, df_new], ignore_index=True)
        df_combined.drop_duplicates(subset=["æ—¥æœŸ"], inplace=True)
        df_combined.sort_values("æ—¥æœŸ", inplace=True)
        df_combined.to_csv(CSV_FILE, index=False, encoding="utf-8-sig")
        logging.info(f"âœ… å·²æ›´æ–°ï¼Œç¸½å…±æœ‰ {len(df_combined)} ç­†è³‡æ–™")
    else:
        df_new.to_csv(CSV_FILE, index=False, encoding="utf-8-sig")
        logging.info("ğŸ“ åˆæ¬¡å»ºç«‹ CSV æª”æ¡ˆ")


# ğŸš€ åŸ·è¡Œ
if __name__ == "__main__":
    update_twse()
